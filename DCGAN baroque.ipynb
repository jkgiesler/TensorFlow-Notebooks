{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGAN implementation in Keras\n",
    "\n",
    "Inspired by jacobgil's implementation: [https://github.com/jacobgil/keras-dcgan/](https://github.com/jacobgil/keras-dcgan) and [http://bamos.github.io/2016/08/09/deep-completion/](http://bamos.github.io/2016/08/09/deep-completion/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function,division\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Activation,Flatten\n",
    "# from keras.layers import Deconvolution2D as Deconv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import mnist\n",
    "from tqdm import tqdm_notebook \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://bamos.github.io/data/2016-08-09/gen-architecture.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url = \"http://bamos.github.io/data/2016-08-09/gen-architecture.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://bamos.github.io/data/2016-08-09/discrim-architecture.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url = \"http://bamos.github.io/data/2016-08-09/discrim-architecture.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO(jkg): add better descriptions of models\n",
    "\n",
    "def keras_generator_model():\n",
    "    '''generate images\n",
    "    '''\n",
    "    model = Sequential()\n",
    "    ##########\n",
    "    model.add(Dense(input_dim = 100, output_dim = 1024*4*4))\n",
    "    model.add(Activation('tanh'))\n",
    "    print(model.output_shape)\n",
    "    model.add(Reshape((1024,4,4),input_shape=(1024*4*4,)))\n",
    "    print(model.output_shape)\n",
    "    model.add(UpSampling2D(size=(4,4)))\n",
    "    model.add(Convolution2D(512,5,5,subsample=(2,2),border_mode = 'same'))\n",
    "    model.add(BatchNormalization(mode=2,axis=3,epsilon=1e-5))\n",
    "    model.add(Activation('tanh'))\n",
    "    print(model.output_shape)\n",
    "    ##########\n",
    "    model.add(UpSampling2D(size=(4,4)))\n",
    "    model.add(Convolution2D(256,5,5,subsample=(2,2),border_mode = 'same'))\n",
    "    model.add(BatchNormalization(mode=2,axis=3,epsilon=1e-5))\n",
    "    model.add(Activation('tanh'))\n",
    "    print(model.output_shape)\n",
    "    ##########\n",
    "    model.add(UpSampling2D(size=(4,4)))\n",
    "    model.add(Convolution2D(128,5,5,subsample=(2,2),border_mode = 'same'))\n",
    "    model.add(BatchNormalization(mode=2,axis=3,epsilon=1e-5))\n",
    "    model.add(Activation('tanh'))\n",
    "    print(model.output_shape)\n",
    "    ##########\n",
    "    model.add(UpSampling2D(size=(4,4)))\n",
    "    model.add(Convolution2D(3,5,5,subsample=(2,2),border_mode = 'same'))\n",
    "    model.add(BatchNormalization(mode=2,axis=3,epsilon=1e-5))\n",
    "    model.add(Activation('tanh'))\n",
    "    print(model.output_shape)\n",
    "    return model\n",
    "\n",
    "def keras_discriminator_model():\n",
    "    '''discriminate images\n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(64, 5, 5,border_mode = 'same',input_shape = (3,64,64)))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    print(model.output_shape)\n",
    "    ##########\n",
    "    model.add(Convolution2D(128, 5, 5,border_mode = 'same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    print(model.output_shape)\n",
    "    ###########\n",
    "    model.add(Convolution2D(256, 5, 5,border_mode = 'same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    print(model.output_shape)\n",
    "    ###########\n",
    "    model.add(Convolution2D(512, 5, 5,border_mode = 'same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    print(model.output_shape)\n",
    "    model.add(Flatten())\n",
    "    print(model.output_shape)\n",
    "    model.add(Dense(1024))\n",
    "    print(model.output_shape)\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    print(model.output_shape)\n",
    "    return model\n",
    "\n",
    "def generator_and_discriminator(gen_model,dis_model):\n",
    "    '''stack the generator model on top of the discriminator model\n",
    "    only allow the generator model to be trainable\n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(gen_model)\n",
    "    dis_model.trainable = False\n",
    "    model.add(dis_model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 16384)\n",
      "(None, 1024, 4, 4)\n",
      "(None, 512, 8, 8)\n",
      "(None, 256, 16, 16)\n",
      "(None, 128, 32, 32)\n",
      "(None, 3, 64, 64)\n",
      "----------\n",
      "(None, 64, 32, 32)\n",
      "(None, 128, 16, 16)\n",
      "(None, 256, 8, 8)\n",
      "(None, 512, 4, 4)\n",
      "(None, 8192)\n",
      "(None, 1024)\n",
      "(None, 1)\n"
     ]
    }
   ],
   "source": [
    "gen = keras_generator_model()\n",
    "gen.output_shape\n",
    "print('----------')\n",
    "desc = keras_discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_images(generated_images):\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num)/width))\n",
    "    shape = generated_images.shape[2:]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[0, :, :]\n",
    "    return image\n",
    "\n",
    "## print nice images\n",
    "def diagnostic_image(gen,epoch):\n",
    "    batch_size = 25\n",
    "    noise = np.zeros((batch_size*20,100))\n",
    "    for i in range(noise.shape[0]):\n",
    "        noise[i,:] = np.random.uniform(-1,1,100)\n",
    "    generated_images = gen.predict(noise,verbose=0)\n",
    "    image = combine_images(generated_images)\n",
    "    image = image * 127.5 + 127.5\n",
    "    Image.fromarray(image.astype(np.uint8)).save(\"epoch_{}.png\".format(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model w/ MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Normalize and Reshape data\n",
    "# (X_train,y_train),(X_test,y_test) = mnist.load_data()\n",
    "\n",
    "# # why do this instead of convert to [0,1] - center and scale not just scale\n",
    "# X_train_n = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "# # X_train = X_train / 255 <-\n",
    "\n",
    "# X_train_n = X_train_n.reshape((X_train.shape[0],1,X_train.shape[1],X_train.shape[2]))\n",
    "# # new shape should be (60000,1,28,28) 1 channel image 28x28 px\n",
    "# X_train_n.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model w/ actual art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "\n",
    "with open('shrunk_baroque.pkl','rb') as f:\n",
    "    imgs = pickle.load(f)\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# want(samples,3,100,100)\n",
    "imgs = imgs * 255\n",
    "imgs = imgs.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = Image.fromarray(imgs[4])\n",
    "img.save('bartest.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs_n = (imgs.astype(np.float32)-127.5)/127.5\n",
    "imgs_n = imgs_n.reshape((imgs.shape[0],3,imgs.shape[1],imgs.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgs_n.shape\n",
    "X_train_n = imgs_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint_folder = 'chk/'\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "batchs_per_epoch = int(X_train_n.shape[0]/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 64, 32, 32)\n",
      "(None, 128, 16, 16)\n",
      "(None, 256, 8, 8)\n",
      "(None, 512, 4, 4)\n",
      "(None, 8192)\n",
      "(None, 1024)\n",
      "(None, 1)\n",
      "(None, 16384)\n",
      "(None, 1024, 4, 4)\n",
      "(None, 512, 8, 8)\n",
      "(None, 256, 16, 16)\n",
      "(None, 128, 32, 32)\n",
      "(None, 3, 64, 64)\n",
      "(None, 3, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Models\n",
    "desc = keras_discriminator_model()\n",
    "gen = keras_generator_model()\n",
    "d_on_g = generator_and_discriminator(gen,desc)\n",
    "\n",
    "d_op = SGD(lr = 5e-4,momentum = 0.9,nesterov=True)\n",
    "g_op = SGD(lr = 5e-4,momentum = 0.9,nesterov=True)\n",
    "\n",
    "gen.compile(loss='binary_crossentropy',optimizer = \"SGD\")\n",
    "print(gen.output_shape)\n",
    "d_on_g.compile(loss='binary_crossentropy',optimizer = g_op)\n",
    "\n",
    "desc.trainable = True # necessary??\n",
    "desc.compile(loss='binary_crossentropy',optimizer= d_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noise = np.zeros((batch_size,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epoch_loss = []\n",
    "for epoch in tqdm_notebook(range(epochs),desc = 'epoch'):\n",
    "    batch_loss = []\n",
    "    for batch_index in tqdm_notebook(range(batchs_per_epoch),desc = 'batch',leave=False):\n",
    "        #build noise up\n",
    "        for sample in range(batch_size):\n",
    "            noise[sample,:] = np.random.uniform(-1,1,100)\n",
    "        \n",
    "        image_set = X_train_n[batch_index*batch_size:(batch_index+1)*batch_size]\n",
    "        # print(image_set.shape)\n",
    "        # feed noise into generator network\n",
    "        gen_images = gen.predict(noise,verbose=0)\n",
    "        # print(gen_images.shape)\n",
    "        # now we have data for our desc network\n",
    "        X_desc = np.concatenate([image_set,gen_images],axis=0)\n",
    "        y = [1] * batch_size + [0] * batch_size\n",
    "        \n",
    "        # train desc\n",
    "        d_loss = desc.train_on_batch(X_desc,y)\n",
    "        \n",
    "        #build noise up\n",
    "        for sample in range(batch_size):\n",
    "            noise[sample,:] = np.random.uniform(-1,1,100)\n",
    "            \n",
    "        # train generator on improved desc\n",
    "        desc.trainable = False\n",
    "        g_loss = d_on_g.train_on_batch(noise,[1] * batch_size)\n",
    "        desc.trainable = True\n",
    "        \n",
    "        if(batch_index+1 == batchs_per_epoch):\n",
    "            gen.save_weights(checkpoint_folder+'g_weights.h5',overwrite=True)\n",
    "            desc.save_weights(checkpoint_folder+'d_weights.h5',overwrite=True)\n",
    "        batch_loss.append([d_loss,g_loss])\n",
    "    #if epoch % 5 == 0:\n",
    "    diagnostic_image(gen,epoch)\n",
    "    avg_d = np.mean([x[0] for x in batch_loss])\n",
    "    avg_g = np.mean([x[1] for x in batch_loss])\n",
    "    print('avg desc loss {} || avg gen loss {}'.format(avg_d,avg_g))\n",
    "    epoch_loss.append([avg_d,avg_g])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![all_img.png](all_img.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
